{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imrohitkr/urbandelights/blob/main/Backend/summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet pytorch_lightning\n",
        "!pip install --quiet  transformers\n",
        "!pip install --quiet  seaborn\n",
        "!pip install --quiet  wget"
      ],
      "metadata": {
        "id": "UuN9yETpSaVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ea6046-876c-4280-dcac-0d6671ed0bd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.6/801.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored\n",
        "import textwrap\n",
        "\n",
        "\n",
        "from transformers import AdamW, T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "sns.set(style='whitegrid',palette='muted',font_scale=1.2)\n",
        "rcParams['figure.figsize'] = 16, 6"
      ],
      "metadata": {
        "id": "nooI18bsShFr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phkT0Y7vSkWh",
        "outputId": "74b164c0-0ed3-4a58-d34e-fb6dc7d70eae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'Review_for_sum.csv'"
      ],
      "metadata": {
        "id": "RtpJ3wN1SmHr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(url,encoding='utf-8')"
      ],
      "metadata": {
        "id": "7iD343inSwmA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "0sIPQMz2SxlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"Text\",\"Summary\"]]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SlW3Bq2ZSz9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "CrNK8sJkS8Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = [\"text\", \"summary\"]\n",
        "df = df.dropna()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ULvxeXejS9C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "LFeSeiReTA0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df,test_size=0.1)\n",
        "train_df.shape,test_df.shape"
      ],
      "metadata": {
        "id": "np-VWpb1TDBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Download NLTK resources (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize the Porter stemmer and stopwords list\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to preprocess text (remove stopwords and perform stemming)\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords and perform stemming\n",
        "    filtered_words = [stemmer.stem(word) for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Join the filtered words back into a single string\n",
        "    preprocessed_text = ' '.join(filtered_words)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to the text column in the dataframe\n",
        "train_df['preprocessed_text'] = train_df['text'].apply(preprocess_text)\n",
        "test_df['preprocessed_text'] = test_df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "I3KunsMfqH_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResSummaryDataset(Dataset):\n",
        "    def __init__(\n",
        "      self,\n",
        "      data : pd.DataFrame,\n",
        "      tokennizer : T5Tokenizer,\n",
        "      text_max_token_len : 512,\n",
        "      summary_max_token_len : 128):\n",
        "\n",
        "      self.tokennizer = tokennizer\n",
        "      self.data = data,\n",
        "      self.text_max_token_len = text_max_token_len\n",
        "      self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index : int):\n",
        "      data_row = self.data[0].iloc[index]\n",
        "      text = data_row[\"text\"]\n",
        "\n",
        "      text_encoding = self.tokennizer(\n",
        "          text,\n",
        "          max_length = self.text_max_token_len,\n",
        "          padding = \"max_length\",\n",
        "          truncation = True,\n",
        "          return_attention_mask = True,\n",
        "          return_tensors = \"pt\"\n",
        "      )\n",
        "\n",
        "      summary_encoding = self.tokennizer(\n",
        "          data_row[\"summary\"],\n",
        "          max_length = self.summary_max_token_len,\n",
        "          padding = \"max_length\",\n",
        "          truncation = True,\n",
        "          return_attention_mask = True,\n",
        "          return_tensors = \"pt\"   # Return PyTorch tensors\n",
        "      )\n",
        "\n",
        "      labels = summary_encoding[\"input_ids\"]\n",
        "      labels[labels==0] = -100\n",
        "\n",
        "      return dict(\n",
        "          text = text,\n",
        "          summary = data_row[\"summary\"],\n",
        "          text_input_ids = text_encoding[\"input_ids\"].flatten(),\n",
        "          text_attention_mask = text_encoding[\"attention_mask\"].flatten(),\n",
        "          labels = labels.flatten(),\n",
        "          labels_attention_mask = summary_encoding[\"attention_mask\"].flatten()\n",
        "      )"
      ],
      "metadata": {
        "id": "Pd7AmF39TLXb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResSummaryDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_df : pd.DataFrame,\n",
        "        test_df : pd.DataFrame,\n",
        "        tokenizer: T5Tokenizer,\n",
        "        batch_size : int  = 8,\n",
        "        text_max_token_len : int = 512,\n",
        "        summary_max_token_len :int = 128\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text_max_token_len = text_max_token_len\n",
        "        self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "    # LightningModule.setup(stage=None)\n",
        "    # Called at the beginning of fit (train + validate), validate, test, or predict.\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "\n",
        "        self.train_dataset = ResSummaryDataset(\n",
        "            self.train_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len)\n",
        "\n",
        "        self.test_dataset = ResSummaryDataset(\n",
        "            self.test_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle= True,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle= False,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle= False,\n",
        "            num_workers=2\n",
        "        )"
      ],
      "metadata": {
        "id": "ly5AeosTTLUG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"t5-base\"\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "tdQuLWgJUA18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_token_counts = []\n",
        "summary_token_counts = []\n",
        "\n",
        "for _, row in train_df.iterrows():\n",
        "\n",
        "    text_token_count = len(tokenizer.encode(row[\"text\"]))\n",
        "    text_token_counts.append(text_token_count)\n",
        "\n",
        "    summary_token_count = len(tokenizer.encode(row[\"summary\"]))\n",
        "    summary_token_counts.append(summary_token_count)"
      ],
      "metadata": {
        "id": "T4FQjVVnUFxu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "data_module = ResSummaryDataModule(train_df,test_df,tokenizer,batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "5TphJ2JvUGeS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResSummaryModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME,return_dict=True)\n",
        "\n",
        "    def forward(self,input_ids,attention_mask,decoder_attention_mask, labels=None):\n",
        "\n",
        "        output = self.model(\n",
        "            input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            labels = labels,\n",
        "            decoder_attention_mask = decoder_attention_mask\n",
        "        )\n",
        "\n",
        "        return output.loss, output.logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        input_ids = batch[\"text_input_ids\"]\n",
        "        attention_mask = batch[\"text_attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_attention_mask = labels_attention_mask,\n",
        "            labels = labels\n",
        "        )\n",
        "\n",
        "        self.log(\"train_loss\",loss,prog_bar=True,logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        input_ids = batch[\"text_input_ids\"]\n",
        "        attention_mask = batch[\"text_attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_attention_mask = labels_attention_mask,\n",
        "            labels = labels\n",
        "        )\n",
        "\n",
        "        self.log(\"val_loss\",loss,prog_bar=True,logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        input_ids = batch[\"text_input_ids\"]\n",
        "        attention_mask = batch[\"text_attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_attention_mask = labels_attention_mask,\n",
        "            labels = labels\n",
        "        )\n",
        "\n",
        "        self.log(\"test_loss\",loss,prog_bar=True,logger=True)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(),lr = 0.0001)"
      ],
      "metadata": {
        "id": "Q3guKeKNUMtQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResSummaryModel()"
      ],
      "metadata": {
        "id": "T0xhSecyUb0J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUZAg1UwSHZV",
        "outputId": "dba06e2c-9778-4bd9-f2f6-f1ba0e5afcd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr 11 10:00:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwjSeJl2Uepl",
        "outputId": "de3ee0e6-11e1-43bf-a231-f258c23e679f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=\"checkpoints\",\n",
        "    filename=\"best-checkpoint\",\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_loss\",name=\"res-summary\")\n",
        "\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    logger=logger,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    max_epochs=N_EPOCHS,\n",
        "    accelerator=\"auto\",\n",
        "    enable_progress_bar=True\n",
        ")"
      ],
      "metadata": {
        "id": "GBhDZ18VUk1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model,datamodule = data_module)"
      ],
      "metadata": {
        "id": "GYTG0kK-UiPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = ResSummaryModel.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "\n",
        "trained_model.freeze()"
      ],
      "metadata": {
        "id": "N0HtEKNHUtE2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text):\n",
        "    device = trained_model.device  # Get the device of the trained model\n",
        "\n",
        "    text_encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Move input tensors to the same device as the trained model\n",
        "    text_encoding = {key: value.to(device) for key, value in text_encoding.items()}\n",
        "\n",
        "    generated_ids = trained_model.model.generate(\n",
        "        input_ids=text_encoding[\"input_ids\"],\n",
        "        attention_mask=text_encoding[\"attention_mask\"],\n",
        "        max_length=150,\n",
        "        num_beams=2,\n",
        "        repetition_penalty=2.5,\n",
        "        length_penalty=1.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    # Move generated_ids back to CPU if it was on GPU\n",
        "    generated_ids = generated_ids.cpu() if device.type == 'cuda' else generated_ids\n",
        "\n",
        "    preds = [tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "             for gen_id in generated_ids]\n",
        "\n",
        "    return \" \".join(preds)"
      ],
      "metadata": {
        "id": "dMpmcm_tWYKX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "_SPk2bN0Whsw",
        "outputId": "557758cb-8dfc-4f19-ef97-c01bfe46db0e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I've ordered these before and I am still thrilled with the product.  They are fresh, soft and very fragrant.  I use a lot of vanilla bean because my family loves vanilla sauce and baked goods made with the fresh bean.  You must seal these very tightly to keep them soft (I use the seal-a-meal), but with care, they will stay nice for months and you can't beat the price!  McCormick sells vanilla beans in a jar and you get two or three beans for anywhere up to $6! And the quality isn't anywhere near what these are.  I will continue to buy this product.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_text(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wJr4fdsUWjbK",
        "outputId": "f406f6d4-4cb4-484b-9089-7df6d007c4a8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i've ordered these before and I am still thrilled with the product. They are fresh, soft and very fragrant.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''I have been to your delightful restaurant twice in the past two weeks. The dishes were beautiful, and every bite was heavenly.\n",
        "I had the seasonal curried chicken crepe on both occasions, and it is honestly the best tasting dish I have ever had. The complexity of the\n",
        "flavor profile was impeccable!  I paired it with the triple cream brie and pear salad, and she was also divine. The greens were so crisp and vibrant,\n",
        "as if they were pulled from a Cezanne painting and plated. The watermelon radish and cucumber scalloped edges did not go unnoticed and the whisper of\n",
        "sweetness from the candied walnuts and port gastrique was the perfect balance to the savory lardons. I even asked our lovely server, Angie, if the chef\n",
        "could prepare a side of the nightly greens, and both times they were delivered without hesitation and delectable. I cannot recommend this jewel of\n",
        "Columbia enough. An exceptional culinary experience is waiting for you just over the bridge. Merci Beaucoup for your talent and hospitality'''"
      ],
      "metadata": {
        "id": "fOrKF24tWrum"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_text(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "OwHEgBsVW3p6",
        "outputId": "7d0e6220-dfa0-47e6-d769-cb324cf81229"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the seasonal curried chicken crepe is honestly the best tasting dish I have ever had. the greens were crisp and vibrant, as if they were pulled from a Cezanne painting and plated.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aaEdXh1TqlM-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}